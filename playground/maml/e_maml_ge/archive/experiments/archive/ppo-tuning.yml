%YAML 1.2
---
config:
  # 8 gives better usage of i7 CPU.
  max_concurrent: 4
env:
  DISPLAY: ":1"
  PYTHONPATH: $HOME/machine_learning/meta_learning_project/packages
run: |
  {env} python e_maml_ge.py {args}
default_args:
  # experiment parameters
  term_reward_threshold: -2000.0
  run_mode: "baselines" # one of ['maml", "e_maml", "baselines"]
  log_directory: "../test_runs/baselines/n_updates_per_batch/{time:%Y-%m-%d}-{time:%H%M%S.%f}/"
  env_name: HalfCheetah-v1
  start_seed: 42
  render: false
  eval_plot_interval: 1 # "interval for plotting the loss"
  eval_save_interval: 10 # "interval for saving plot figure"
  # Training Parameters
  n_tasks: 40
  n_grad_steps: 1
  n_epochs: 1000
  n_parallel_envs: 8
  env_horizon_max_steps: 128
  n_updates_per_batch: 1
  alpha: 0.05
  beta: 0.05
  # model parameters
  first_order: false
  inner_alg: PPO
  inner_optimizer: Adam
  meta_alg: PPO
  eval_grad_steps:  "0 1"
  num_grad_steps: 1
  # Model Options (PPO)
  vf_coef: 0.5
  ent_coef: 0.0
  max_grad_norm: 0.5
  clip_range: 0.2
  # GAE parameters
  gamma: 0.99
  lam: 0.95
batch_args: # use good typing convention here
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 16 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 4 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 1 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 16 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 4 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 1 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 16 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 4 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
  - eval_plot_interval: 5
    inner_alg: PPO
    n_parallel_envs: 8
    env_horizon_max_steps: 128
    n_updates_per_batch: 1 # 16, 4, 1
    alpha: 0.0003
    clip_range: 0.2
#  - eval_plot_interval: 5
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.003
#  - eval_plot_interval: 5
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.01
#  - eval_plot_interval: 5
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.03
#  - eval_plot_interval: 5
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 4
#    alpha: 0.0003
#  - eval_plot_interval: 5
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 16
#    alpha: 0.0003
#  - eval_plot_interval: 1
#    n_epochs: 3000
#    inner_alg: PPO
#    n_parallel_envs: 1
#    env_horizon_max_steps: 1024
#    n_updates_per_batch: 16
#    alpha: 0.0003
#  - eval_plot_interval: 1
#    n_epochs: 3000
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 1024
#    n_updates_per_batch: 64
#    alpha: 0.0003
#  - eval_plot_interval: 1
#    n_epochs: 3000
#    inner_alg: PPO
#    n_parallel_envs: 16
#    env_horizon_max_steps: 64
#    n_updates_per_batch: 16
#    alpha: 0.0003
#  - eval_plot_interval: 1
#    vf_coef: 0.0325
#    n_epochs: 500
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.0003
#    clipe_range: 0.2
#  - eval_plot_interval: 1
#    vf_coef: 0.0325
#    n_epochs: 500
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.003
#    clipe_range: 0.2
#  - eval_plot_interval: 1
#    vf_coef: 0.0325
#    n_epochs: 500
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.03
#    clipe_range: 0.2
#  - eval_plot_interval: 1
#    vf_coef: 0.0325
#    n_epochs: 500
#    inner_alg: PPO
#    n_parallel_envs: 8
#    env_horizon_max_steps: 128
#    n_updates_per_batch: 1
#    alpha: 0.1
#    clipe_range: 0.2
